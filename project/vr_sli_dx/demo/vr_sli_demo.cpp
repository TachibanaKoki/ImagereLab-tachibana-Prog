//----------------------------------------------------------------------------------
// File:        vr_sli_demo/vr_sli_demo.cpp
// SDK Version: 2.1
// Email:       vrsupport@nvidia.com
// Site:        http://developer.nvidia.com/
//
// Copyright (c) 2016, NVIDIA CORPORATION. All rights reserved.
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions
// are met:
//  * Redistributions of source code must retain the above copyright
//    notice, this list of conditions and the following disclaimer.
//  * Redistributions in binary form must reproduce the above copyright
//    notice, this list of conditions and the following disclaimer in the
//    documentation and/or other materials provided with the distribution.
//  * Neither the name of NVIDIA CORPORATION nor the names of its
//    contributors may be used to endorse or promote products derived
//    from this software without specific prior written permission.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
// EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
// PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
// CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
// EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
// PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
// OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
//
//----------------------------------------------------------------------------------

#include <framework.h>
#include <AntTweakBar.h>
#include <nvapi.h>
#include <xinput.h>
#include <algorithm>
#include <OVR_CAPI_D3D.h>
#include <openvr.h>

#include "shadow.h"
#include "shader-common.h"

// Shader bytecode generated by build process
#include "simple_ps.h"
#include "simple_alphatest_ps.h"
#include "shadow_alphatest_ps.h"
#include "tonemap_ps.h"
#include "world_vs.h"

using namespace util;
using namespace Framework;

#pragma warning(disable: 4351)	// "new behavior: elements of array will be default initialized"

#define CHECK_NVAPI(f) \
		{ \
			NvAPI_Status status = f; \
			CHECK_ERR_MSG(status == NVAPI_OK, "NvAPI call failed with error code: %d\nFailed call: %s", status, #f); \
		}

#define CHECK_NVAPI_WARN(f) \
		{ \
			NvAPI_Status status = f; \
			CHECK_WARN_MSG(status == NVAPI_OK, "NvAPI call failed with error code: %d\nFailed call: %s", status, #f); \
		}

#define CHECK_OVR(f) \
		{ \
			ovrResult result = f; \
			if (OVR_FAILURE(result)) \
			{ \
				ovrErrorInfo errorInfo; \
				ovr_GetLastErrorInfo(&errorInfo); \
				ERR("LibOVR call failed with error code: %d\nFailed call: %s\nError message: %s", result, #f, errorInfo.ErrorString); \
			} \
		}

#define CHECK_OVR_WARN(f) \
		{ \
			ovrResult result = f; \
			if (OVR_FAILURE(result)) \
			{ \
				ovrErrorInfo errorInfo; \
				ovr_GetLastErrorInfo(&errorInfo); \
				WARN("LibOVR call failed with error code: %d\nFailed call: %s\nError message: %s", result, #f, errorInfo.ErrorString); \
			} \
		}

// Define error checkers for OpenVR APIs
#define CHECK_OPENVR_WARN(f) \
		{ \
			vr::EVRCompositorError result = f; \
			ASSERT_WARN_MSG(result == vr::VRCompositorError_None, "OpenVR call failed with error code: %d\nFailed call: %s", result, #f); \
		}



// Globals

float3 g_vecDirectionalLight = normalize(makefloat3(0.5f, 10.0f, 1.5f));
rgb g_rgbDirectionalLight = makergb(1.1f, 1.0f, 0.7f);
rgb g_rgbSky = makergb(0.44f, 0.56f, 1.0f);
float g_shadowFilterWidth = 0.01f;		// meters
float g_normalOffsetShadow = 1e-5f;		// meters
float g_exposure = 1.1f;

// Render target sizes
int2 g_dimsEyeView;						// Base pixel dims of one eye view
float g_supersampleFactor = 1.0f;		// Scales render target size
int2 g_dimsPreWarp;						// Final pixel dims, including supersample factor, for both eyes side-by-side

bool g_vsync = true;
int g_repeatRenderingCount = 1;

float g_debugSlider0 = 0.0f;
float g_debugSlider1 = 0.0f;
float g_debugSlider2 = 0.0f;
float g_debugSlider3 = 0.0f;



// Constant buffers

typedef matrix<float, 3, 4> float3x4;

struct CBFrame								// matches cbuffer CBFrame in shader-common.h
{
	float4x4	m_matWorldToClip;
	float4x4	m_matWorldToUvzwShadow;
	float3x4	m_matWorldToUvzShadowNormal;	// actually float3x3, but constant buffer packing rules...
	point3		m_posCamera;
	float		m_padding0;

	float3		m_vecDirectionalLight;
	float		m_padding1;

	rgb			m_rgbDirectionalLight;
	float		m_padding2;

	float3		m_shadowFilterUVZScale;
	float		m_normalOffsetShadow;

	float		m_exposure;					// Exposure multiplier
};

struct CBDebug								// matches cbuffer CBDebug in shader-common.h
{
	float		m_debugKey;					// Mapped to spacebar and controller A button - 0 if up, 1 if down
	float		m_debugSlider0;				// Mapped to debug sliders in UI
	float		m_debugSlider1;				// ...
	float		m_debugSlider2;				// ...
	float		m_debugSlider3;				// ...
};



// Main application class

enum GTS	// GPU Timestamp
{
	GTS_Scene,
	GTS_CrossGPUCopy,

	GTS_Count,
};

enum HMDSTATE
{
	HMDSTATE_Unavailable,
	HMDSTATE_Available,
	HMDSTATE_Connected,

	HMDSTATE_Count,
};

class VRSLIDemo : public D3D11Window
{
public:
	typedef D3D11Window super;

									VRSLIDemo();

	bool							Init(HINSTANCE hInstance);
	virtual void					Shutdown() override;
	virtual LRESULT					MsgProc(HWND hWnd, UINT message, WPARAM wParam, LPARAM lParam) override;
	virtual void					OnResize(int2_arg dimsNew) override;
	virtual void					OnRender() override;

	Timer							m_timer;
	void							ResetCameras();

	// Common stuff for rendering 3D scenes
	void							SetRenderTargetDimsToMatchWindow();
	void							UpdateRenderTargetDims();
	void							EnsureRenderTargetsAlloced();
	affine3							GetEyeToCameraTransform(int eye);
	void							DrawMaterials(ID3D11PixelShader * pPs, ID3D11PixelShader * pPsAlphaTest);
	void							RenderScene();
	void							RenderShadowMap();
	RenderTarget					m_rtPreWarpMSAA;
	DepthStencilTarget				m_dstPreWarpMSAA;
	RenderTarget					m_rtPreWarp;
	comptr<ID3D11ShaderResourceView>m_pSrvPreWarpRaw;	// Non-SRGB SRV
	comptr<ID3D11RenderTargetView>	m_pRtvPreWarpRaw;	// Non-SRGB RTV
	ShadowMap						m_shmp;
	comptr<ID3D11VertexShader>		m_pVsWorld;
	comptr<ID3D11PixelShader>		m_pPsSimple;
	comptr<ID3D11PixelShader>		m_pPsSimpleAlphaTest;
	comptr<ID3D11PixelShader>		m_pPsShadowAlphaTest;
	comptr<ID3D11PixelShader>		m_pPsTonemap;
	comptr<ID3D11InputLayout>		m_pInputLayout;
	CB<CBFrame>						m_cbFrame[2];
	CB<CBDebug>						m_cbDebug;
	Texture2D						m_tex1x1Black;
	Texture2D						m_tex1x1White;
	Texture2D						m_tex1x1FlatNormal;
	GPUProfiler						m_gpup;
	float4x4						m_matProj[2];

	// Rendering Crytek Sponza
	bool							InitCrytekSponza();
	Mesh							m_meshCrytekSponza;
	MaterialLib						m_mtlLibCrytekSponza;
	TextureLib						m_texLibCrytekSponza;
	FPSCamera						m_camCrytekSponza;

	// Oculus HMD support
	bool							TryActivateOculusHMD();
	void							DeactivateOculusHMD();
	HMDSTATE						m_oculusHMDState;
	ovrSession						m_oculusSession;
	ovrTextureSwapChain                 m_oculusTextureSwapChain;
	ovrFovPort						m_eyeFovOculusHMD[2];
	ovrVector3f						m_eyeOffsetsOculusHMD[2];
	ovrPosef						m_poseOculusHMD[2];
	std::vector<comptr<ID3D11RenderTargetView>> m_oculusSwapTextureRTVs;

	// OpenVR HMD support
	bool							TryActivateOpenVRHMD();
	void							DeactivateOpenVRHMD();
	HMDSTATE						m_openVRHMDState;
	vr::IVRSystem*					m_pOpenVRHMD;
	vr::IVRCompositor*				m_pCompositorOpenVRHMD;
	vr::TrackedDevicePose_t			m_trackedDevicePoseOpenVRHMD[vr::k_unMaxTrackedDeviceCount];
	affine3							m_poseOpenVRHMD;

	// Screenshots
	void							SaveScreenshot(RenderTarget * pRt, const char * suggestedFilename);

	// VR SLI
	bool							m_vrSliMode;
	bool							m_useBroadcastSLI;
	ID3D11MultiGPUDevice*			m_pMultiGPUDevice;
	NV_MULTIGPU_CAPS				m_multiGPUCaps;
};

// VRSLIDemo implementation

VRSLIDemo::VRSLIDemo()
:	super(),
	m_oculusHMDState(HMDSTATE_Unavailable),
	m_oculusSession(nullptr),
	m_openVRHMDState(HMDSTATE_Unavailable),
	m_pOpenVRHMD(nullptr),
	m_pCompositorOpenVRHMD(nullptr),
	m_vrSliMode(false),
	m_useBroadcastSLI(true),
	m_pMultiGPUDevice(nullptr)
{
	// Don't set up a depth buffer for the main window, since all 3D rendering will be done to other targets
	m_hasDepthBuffer = false;
}

bool VRSLIDemo::Init(HINSTANCE hInstance)
{
	// Init VR SLI
	CHECK_NVAPI(NvAPI_D3D11_MultiGPU_GetCaps(&m_multiGPUCaps));
	if (m_multiGPUCaps.nSLIGPUs > 1)
	{
		// Enable VR-SLI driver layer, before device is created
		CHECK_NVAPI(NvAPI_D3D11_MultiGPU_Init(true));
		m_vrSliMode = true;
	}

	// Init libovr
	ovrInitParams ovrParams = {};
	if (OVR_FAILURE(ovr_Initialize(&ovrParams)))
	{
		MessageBox(m_hWnd, "Couldn't init Oculus SDK; HMD support will not be available", "Warning", MB_OK);
	}

	super::Init("VRSLIDemo", "VR SLI Demo", hInstance);

	if (m_vrSliMode)
	{
		ULONG currentVersion;
		UINT maxGPUs = 2;
		CHECK_NVAPI(NvAPI_D3D11_CreateMultiGPUDevice(m_pDevice, ID3D11MultiGPUDevice_VER, &currentVersion, &m_pMultiGPUDevice, maxGPUs));
		ASSERT_ERR(currentVersion >= ID3D11MultiGPUDevice_VER);
	}

	// Configure device for minimum latency and highest priority
	comptr<IDXGIDevice1> pDXGIDevice;
	if (SUCCEEDED(m_pDevice->QueryInterface(__uuidof(IDXGIDevice1), (void **)&pDXGIDevice)))
	{
		CHECK_D3D(pDXGIDevice->SetMaximumFrameLatency(1));
		CHECK_D3D(pDXGIDevice->SetGPUThreadPriority(7));
	}

	// Init GPU profiler
	m_gpup.Init(m_pDevice, GTS_Count);

	// Init AntTweakBar
	CHECK_ERR(TwInit(TW_DIRECT3D11, m_pDevice));

	// Automatically use the biggest font size
	TwDefine("GLOBAL fontsize=3 fontresizable=false");

	// Create bar for FPS display
	TwBar * pTwBarFPS = TwNewBar("FPS");
	TwDefine("FPS position='15 15' size='330 130' valueswidth=100 refresh=0.5");
	TwAddVarCB(
			pTwBarFPS, "FPS", TW_TYPE_FLOAT,
			nullptr,
			[](void * value, void * timestep) {
				*(float *)value = 1.0f / *(float *)timestep;
			},
			&m_timer.m_timestep,
			"precision=1");
	TwAddVarCB(
			pTwBarFPS, "Frame time (ms)", TW_TYPE_FLOAT,
			nullptr,
			[](void * value, void * timestep) {
				*(float *)value = 1000.0f * *(float *)timestep;
			},
			&m_timer.m_timestep,
			"precision=2");
	TwAddSeparator(pTwBarFPS, nullptr, nullptr);
	TwAddVarCB(
			pTwBarFPS, "Scene render time (ms)", TW_TYPE_FLOAT,
			nullptr,
			[](void * value, void * gpup) {
				GPUProfiler * pGpup = (GPUProfiler *)gpup;
				*(float *)value = pGpup->m_msAvg[GTS_Scene];
			},
			&m_gpup,
			"precision=2");
	TwAddVarCB(
			pTwBarFPS, "Cross-GPU copy time (ms)", TW_TYPE_FLOAT,
			nullptr,
			[](void * value, void * gpup) {
				GPUProfiler * pGpup = (GPUProfiler *)gpup;
				*(float *)value = pGpup->m_msAvg[GTS_CrossGPUCopy];
			},
			&m_gpup,
			"precision=2");

	// Create bar for rendering options
	TwBar * pTwBarRendering = TwNewBar("Rendering");
	TwDefine("Rendering position='15 160' size='330 140' valueswidth=120");
	TwAddVarCB(
		pTwBarRendering, "Supersample Factor", TW_TYPE_FLOAT, 
		[](const void * value, void * window) {
			g_supersampleFactor = *(float *)value;
			((VRSLIDemo *)window)->UpdateRenderTargetDims();
		},
		[](void * value, void *) {
			*(float *)value = g_supersampleFactor;
		},
		this,
		"min=0.1 max=4.0 step=0.01 precision=2");
	TwAddVarRW(pTwBarRendering, "Repeat Rendering", TW_TYPE_INT32, &g_repeatRenderingCount, "min=1 max=100");
	TwAddVarRW(pTwBarRendering, "VSync", TW_TYPE_BOOLCPP, &g_vsync, nullptr);
	if (m_multiGPUCaps.nSLIGPUs > 1)
	{
		TwAddVarRW(pTwBarRendering, "VR SLI Mode", TW_TYPE_BOOLCPP, &m_vrSliMode, nullptr);
		TwAddVarRW(pTwBarRendering, "Use Broadcast SLI", TW_TYPE_BOOLCPP, &m_useBroadcastSLI, nullptr);
	}

	// Create bar for Oculus HMD connection
	TwBar * pTwBarOculusHMD = TwNewBar("Oculus HMD");
	TwDefine("'Oculus HMD' position='15 315' size='300 100' valueswidth=125 refresh=1.0");
	TwAddButton(
		pTwBarOculusHMD, "Activate Oculus HMD",
		[](void * window) {
			((VRSLIDemo *)window)->TryActivateOculusHMD();
			TwRefreshBar(TwGetBarByName("Oculus HMD"));
		}, this, nullptr);
	TwAddButton(
		pTwBarOculusHMD, "Deactivate Oculus HMD",
		[](void * window) {
			((VRSLIDemo *)window)->DeactivateOculusHMD();
			TwRefreshBar(TwGetBarByName("Oculus HMD"));
		}, this, nullptr);

	// Create bar for OpenVR HMD connection
	TwBar * pTwBarOpenVRHMD = TwNewBar("OpenVR HMD");
	TwDefine("'OpenVR HMD' position='15 430' size='300 100' valueswidth=125 refresh=1.0");
	TwAddButton(
		pTwBarOpenVRHMD, "Activate OpenVR HMD",
		[](void * window) {
			((VRSLIDemo *)window)->TryActivateOpenVRHMD();
			TwRefreshBar(TwGetBarByName("OpenVR HMD"));
		}, this, nullptr);
	TwAddButton(
		pTwBarOpenVRHMD, "Deactivate OpenVR HMD",
		[](void * window) {
			((VRSLIDemo *)window)->DeactivateOpenVRHMD();
			TwRefreshBar(TwGetBarByName("OpenVR HMD"));
		}, this, nullptr);

	// Create bar for screenshots
	TwBar * pTwBarScreenshots = TwNewBar("Screenshots");
	TwDefine("Screenshots position='15 545' size='300 100' valueswidth=15");
	TwAddButton(
			pTwBarScreenshots, "Screenshot Pre-Warp RT",
			[](void * window) {
				VRSLIDemo * pWindow = (VRSLIDemo *)window;
				pWindow->SaveScreenshot(&pWindow->m_rtPreWarp, "prewarp.bmp");
			}, this, nullptr);

#if 0
	// Create bar for debug sliders
	TwBar * pTwBarDebug = TwNewBar("Debug");
	TwDefine("Debug position='15 660' size='225 115' valueswidth=75");
	TwAddVarRW(pTwBarDebug, "g_debugSlider0", TW_TYPE_FLOAT, &g_debugSlider0, "min=0.0 step=0.01 precision=2");
	TwAddVarRW(pTwBarDebug, "g_debugSlider1", TW_TYPE_FLOAT, &g_debugSlider1, "min=0.0 step=0.01 precision=2");
	TwAddVarRW(pTwBarDebug, "g_debugSlider2", TW_TYPE_FLOAT, &g_debugSlider2, "min=0.0 step=0.01 precision=2");
	TwAddVarRW(pTwBarDebug, "g_debugSlider3", TW_TYPE_FLOAT, &g_debugSlider3, "min=0.0 step=0.01 precision=2");
#endif

	// Init shadow map
	m_shmp.Init(m_pDevice, makeint2(4096));

	// Load shaders
	CHECK_D3D(m_pDevice->CreateVertexShader(world_vs_bytecode, dim(world_vs_bytecode), nullptr, &m_pVsWorld));
	CHECK_D3D(m_pDevice->CreatePixelShader(simple_ps_bytecode, dim(simple_ps_bytecode), nullptr, &m_pPsSimple));
	CHECK_D3D(m_pDevice->CreatePixelShader(simple_alphatest_ps_bytecode, dim(simple_alphatest_ps_bytecode), nullptr, &m_pPsSimpleAlphaTest));
	CHECK_D3D(m_pDevice->CreatePixelShader(shadow_alphatest_ps_bytecode, dim(shadow_alphatest_ps_bytecode), nullptr, &m_pPsShadowAlphaTest));
	CHECK_D3D(m_pDevice->CreatePixelShader(tonemap_ps_bytecode, dim(tonemap_ps_bytecode), nullptr, &m_pPsTonemap));

	// Initialize the input layout, and validate it against all the vertex shaders

	D3D11_INPUT_ELEMENT_DESC aInputDescs[] =
	{
		{ "POSITION", 0, DXGI_FORMAT_R32G32B32_FLOAT,    0, UINT(offsetof(Vertex, m_pos)),     D3D11_INPUT_PER_VERTEX_DATA, 0 },
		{ "NORMAL",   0, DXGI_FORMAT_R32G32B32_FLOAT,    0, UINT(offsetof(Vertex, m_normal)),  D3D11_INPUT_PER_VERTEX_DATA, 0 },
		{ "UV",       0, DXGI_FORMAT_R32G32_FLOAT,       0, UINT(offsetof(Vertex, m_uv)),      D3D11_INPUT_PER_VERTEX_DATA, 0 },
		{ "TANGENT",  0, DXGI_FORMAT_R32G32B32A32_FLOAT, 0, UINT(offsetof(Vertex, m_tangent)), D3D11_INPUT_PER_VERTEX_DATA, 0 },
	};
	CHECK_D3D(m_pDevice->CreateInputLayout(
							aInputDescs, dim(aInputDescs),
							world_vs_bytecode, dim(world_vs_bytecode),
							&m_pInputLayout));

	// Init constant buffers
	for (int i = 0; i < dim(m_cbFrame); ++i)
		m_cbFrame[i].Init(m_pDevice);
	m_cbDebug.Init(m_pDevice);

	// Init default textures
	CreateTexture1x1(m_pDevice, makergba(0.0f), &m_tex1x1Black);
	CreateTexture1x1(m_pDevice, makergba(1.0f), &m_tex1x1White);
	CreateTexture1x1(m_pDevice, makergba(0.5f, 0.5f, 1.0f, 0.0f), &m_tex1x1FlatNormal, DXGI_FORMAT_R8G8B8A8_UNORM);

	if (!InitCrytekSponza())
		return false;

	ResetCameras();

	return true;
}

bool VRSLIDemo::InitCrytekSponza()
{
	// Ensure the asset pack is up to date
	static const AssetCompileInfo s_assets[] =
	{
		{ "crytek-sponza/sponza.obj",								ACK_OBJMesh, },
		{ "crytek-sponza/sponza.mtl",								ACK_OBJMtlLib, },
		{ "crytek-sponza/textures/background.tga",					ACK_TextureWithMips, },
		{ "crytek-sponza/textures/background_ddn.tga",				ACK_NormalMapWithMips, },
		{ "crytek-sponza/textures/chain_texture.tga",				ACK_TextureWithMips, },
		{ "crytek-sponza/textures/chain_texture_ddn.tga",			ACK_NormalMapWithMips, },
		{ "crytek-sponza/textures/chain_texture_mask.tga",			ACK_TextureWithMips, },
		{ "crytek-sponza/textures/gi_flag.tga",						ACK_TextureWithMips, },
		{ "crytek-sponza/textures/lion.tga",						ACK_TextureWithMips, },
		{ "crytek-sponza/textures/lion_ddn.tga",					ACK_NormalMapWithMips, },
		{ "crytek-sponza/textures/spnza_bricks_a_diff.tga",			ACK_TextureWithMips, },
		{ "crytek-sponza/textures/spnza_bricks_a_ddn.tga",			ACK_NormalMapWithMips, },
		{ "crytek-sponza/textures/spnza_bricks_a_spec.tga",			ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_arch_diff.tga",			ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_arch_ddn.tga",				ACK_NormalMapWithMips, },
		{ "crytek-sponza/textures/sponza_arch_spec.tga",			ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_ceiling_a_diff.tga",		ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_ceiling_a_spec.tga",		ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_column_a_diff.tga",		ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_column_a_ddn.tga",			ACK_NormalMapWithMips, },
		{ "crytek-sponza/textures/sponza_column_a_spec.tga",		ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_column_b_diff.tga",		ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_column_b_ddn.tga",			ACK_NormalMapWithMips, },
		{ "crytek-sponza/textures/sponza_column_b_spec.tga",		ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_column_c_diff.tga",		ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_column_c_ddn.tga",			ACK_NormalMapWithMips, },
		{ "crytek-sponza/textures/sponza_column_c_spec.tga",		ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_curtain_blue_diff.tga",	ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_curtain_diff.tga",			ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_curtain_green_diff.tga",	ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_details_diff.tga",			ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_details_spec.tga",			ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_fabric_blue_diff.tga",		ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_fabric_diff.tga",			ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_fabric_green_diff.tga",	ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_fabric_spec.tga",			ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_flagpole_diff.tga",		ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_flagpole_spec.tga",		ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_floor_a_diff.tga",			ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_floor_a_spec.tga",			ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_roof_diff.tga",			ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_thorn_diff.tga",			ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_thorn_ddn.tga",			ACK_NormalMapWithMips, },
		{ "crytek-sponza/textures/sponza_thorn_spec.tga",			ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_thorn_mask.tga",			ACK_TextureWithMips, },
		{ "crytek-sponza/textures/vase_ddn.tga",					ACK_NormalMapWithMips, },
		{ "crytek-sponza/textures/vase_dif.tga",					ACK_TextureWithMips, },
		{ "crytek-sponza/textures/vase_hanging.tga",				ACK_TextureWithMips, },
		{ "crytek-sponza/textures/vase_plant.tga",					ACK_TextureWithMips, },
		{ "crytek-sponza/textures/vase_plant_mask.tga",				ACK_TextureWithMips, },
		{ "crytek-sponza/textures/vase_plant_spec.tga",				ACK_TextureWithMips, },
		{ "crytek-sponza/textures/vase_round.tga",					ACK_TextureWithMips, },
		{ "crytek-sponza/textures/vase_round_ddn.tga",				ACK_NormalMapWithMips, },
		{ "crytek-sponza/textures/vase_round_spec.tga",				ACK_TextureWithMips, },
	};

	comptr<AssetPack> pPack = new AssetPack;
	if (!LoadAssetPackOrCompileIfOutOfDate("crytek-sponza-assets.zip", s_assets, dim(s_assets), pPack))
	{
		ERR("Couldn't load or compile Crytek Sponza asset pack");
		return false;
	}

	// Load assets
	if (!LoadTextureLibFromAssetPack(pPack, s_assets, dim(s_assets), &m_texLibCrytekSponza))
	{
		ERR("Couldn't load Crytek Sponza texture library");
		return false;
	}
	if (!LoadMaterialLibFromAssetPack(pPack, "crytek-sponza/sponza.mtl", &m_texLibCrytekSponza, &m_mtlLibCrytekSponza))
	{
		ERR("Couldn't load Crytek Sponza material library");
		return false;
	}
	if (!LoadMeshFromAssetPack(pPack, "crytek-sponza/sponza.obj", &m_mtlLibCrytekSponza, &m_meshCrytekSponza))
	{
		ERR("Couldn't load Crytek Sponza mesh");
		return false;
	}

	// Hardcode a list of alpha-tested materials, for now
	static const char * s_aMtlAlphaTest[] =
	{
		"leaf",
		"material__57",
		"chain",
	};
	for (int i = 0; i < dim(s_aMtlAlphaTest); ++i)
	{
		if (Material * pMtl = m_mtlLibCrytekSponza.Lookup(s_aMtlAlphaTest[i]))
			pMtl->m_alphaTest = true;
	}

	// Upload all assets to GPU
	m_meshCrytekSponza.UploadToGPU(m_pDevice);
	m_texLibCrytekSponza.UploadAllToGPU(m_pDevice);

	// Init the camera
	m_camCrytekSponza.m_moveSpeed = 3.0f;
	m_camCrytekSponza.m_mbuttonActivate = MBUTTON_Left;

	return true;
}

void VRSLIDemo::SetRenderTargetDimsToMatchWindow()
{
	// Set the render target size to match the window
	g_dimsEyeView = makeint2(m_dims.x / 2, m_dims.y);
	UpdateRenderTargetDims();

	// Also update the projection matrices for the new FOV
	m_matProj[0] = perspProjD3DStyle(1.5f, 0.5f * float(m_dims.x) / float(m_dims.y), 0.1f, 1000.0f);
	m_matProj[1] = m_matProj[0];
}

void VRSLIDemo::UpdateRenderTargetDims()
{
	g_dimsPreWarp = max(round(g_supersampleFactor * makefloat2(g_dimsEyeView)), makeint2(1));
	g_dimsPreWarp.x *= 2;
}

void VRSLIDemo::EnsureRenderTargetsAlloced()
{
	if (any(g_dimsPreWarp != m_rtPreWarp.m_dims))
	{
		m_rtPreWarpMSAA.Reset();
		m_dstPreWarpMSAA.Reset();
		m_rtPreWarp.Reset();
		m_pSrvPreWarpRaw.release();
		m_pRtvPreWarpRaw.release();

		m_rtPreWarpMSAA.Init(m_pDevice, g_dimsPreWarp, DXGI_FORMAT_R16G16B16A16_FLOAT, s_msaaSamples);
		m_dstPreWarpMSAA.Init(m_pDevice, g_dimsPreWarp, DXGI_FORMAT_D32_FLOAT, s_msaaSamples);
		m_rtPreWarp.Init(m_pDevice, g_dimsPreWarp, DXGI_FORMAT_R8G8B8A8_UNORM_SRGB);

		// Create a non-SRGB SRV and RTV of the resolved render target
		D3D11_SHADER_RESOURCE_VIEW_DESC srvDesc =
		{
			DXGI_FORMAT_R8G8B8A8_UNORM,
			D3D11_SRV_DIMENSION_TEXTURE2D,
		};
		srvDesc.Texture2D.MipLevels = 1;
		CHECK_D3D(m_pDevice->CreateShaderResourceView(m_rtPreWarp.m_pTex, &srvDesc, &m_pSrvPreWarpRaw));
		D3D11_RENDER_TARGET_VIEW_DESC rtvDesc =
		{
			DXGI_FORMAT_R8G8B8A8_UNORM,
			D3D11_RTV_DIMENSION_TEXTURE2D,
		};
		CHECK_D3D(m_pDevice->CreateRenderTargetView(m_rtPreWarp.m_pTex, &rtvDesc, &m_pRtvPreWarpRaw));
	}
}

void VRSLIDemo::Shutdown()
{
	TwTerminate();
	DeactivateOculusHMD();
	DeactivateOpenVRHMD();

	m_rtPreWarpMSAA.Reset();
	m_dstPreWarpMSAA.Reset();
	m_rtPreWarp.Reset();
	m_pSrvPreWarpRaw.release();
	m_pRtvPreWarpRaw.release();
	m_shmp.Reset();
	m_pVsWorld.release();
	m_pPsSimple.release();
	m_pPsSimpleAlphaTest.release();
	m_pPsShadowAlphaTest.release();
	m_pPsTonemap.release();
	m_pInputLayout.release();
	for (int i = 0; i < dim(m_cbFrame); ++i)
		m_cbFrame[i].Reset();
	m_cbDebug.Reset();
	m_tex1x1Black.Reset();
	m_tex1x1White.Reset();
	m_tex1x1FlatNormal.Reset();
	m_gpup.Reset();

	m_meshCrytekSponza.Reset();
	m_mtlLibCrytekSponza.Reset();
	m_texLibCrytekSponza.Reset();

	if (m_pMultiGPUDevice)
	{
		m_pMultiGPUDevice->Destroy();
		m_pMultiGPUDevice = nullptr;
	}

	super::Shutdown();
	ovr_Shutdown();
	NvAPI_Unload();
}

LRESULT VRSLIDemo::MsgProc(HWND hWnd, UINT message, WPARAM wParam, LPARAM lParam)
{
	// Give AntTweakBar a crack at the message
	if (TwEventWin(hWnd, message, wParam, lParam))
		return 0;

	// Give the camera a crack at the message
	if (m_camCrytekSponza.HandleWindowsMessage(message, wParam, lParam))
		return 0;

	switch (message)
	{
	case WM_KEYDOWN:
		switch (wParam)
		{
		case VK_ESCAPE:
			Shutdown();
			return 0;

		case VK_HOME:
			ResetCameras();
			return 0;

		case 'R':
			if (m_oculusSession)
				ovr_RecenterTrackingOrigin(m_oculusSession);
			else if (m_pOpenVRHMD)
				m_pOpenVRHMD->ResetSeatedZeroPose();
			break;

		default:
			return super::MsgProc(hWnd, message, wParam, lParam);
		}
	default:
		return super::MsgProc(hWnd, message, wParam, lParam);
	}
}

void VRSLIDemo::OnResize(int2_arg dimsNew)
{
	super::OnResize(dimsNew);

	if (!m_oculusSession && !m_pOpenVRHMD)
	{
		SetRenderTargetDimsToMatchWindow();
	}
}

void VRSLIDemo::OnRender()
{
	m_timer.OnFrameStart();

	m_camCrytekSponza.Update(m_timer.m_timestep);

	if (m_oculusSession || m_pOpenVRHMD)
	{
		// Force camera pitch to zero, so pitch is only from HMD orientation
		m_camCrytekSponza.m_pitch = 0.0f;
		m_camCrytekSponza.UpdateOrientation();
	}
	if (m_oculusSession)
	{
		// Retrieve head poses at which to render from OVR tracking system
		ovr_GetEyePoses(m_oculusSession, m_timer.m_frameCount, true, m_eyeOffsetsOculusHMD, m_poseOculusHMD, nullptr);
	}
	else if (m_pOpenVRHMD)
	{
		m_pCompositorOpenVRHMD->WaitGetPoses(m_trackedDevicePoseOpenVRHMD, vr::k_unMaxTrackedDeviceCount, nullptr, 0);

		if (m_trackedDevicePoseOpenVRHMD[vr::k_unTrackedDeviceIndex_Hmd].bPoseIsValid)
		{
			vr::HmdMatrix34_t pose = m_trackedDevicePoseOpenVRHMD[vr::k_unTrackedDeviceIndex_Hmd].mDeviceToAbsoluteTracking;
			m_poseOpenVRHMD = makeaffine3(
								pose.m[0][0], pose.m[1][0], pose.m[2][0],
								pose.m[0][1], pose.m[1][1], pose.m[2][1],
								pose.m[0][2], pose.m[1][2], pose.m[2][2],
								pose.m[0][3], pose.m[1][3], pose.m[2][3]);
		}
	}

	EnsureRenderTargetsAlloced();

	m_gpup.OnFrameStart(m_pCtx);
	m_pCtx->ClearState();
	m_pCtx->RSSetState(m_pRsDefault);

	// Set up whole-frame constant buffers
	XINPUT_STATE controllerState = {};
	{
		static bool controllerPresent = true;
		if (controllerPresent && XInputGetState(0, &controllerState) != ERROR_SUCCESS)
			controllerPresent = false;
	}
	CBDebug cbDebug =
	{
		// !!!UNDONE: move keyboard tracking into an input system that respects focus, etc.
		(GetAsyncKeyState(' ') || (controllerState.Gamepad.wButtons & XINPUT_GAMEPAD_A)) ? 1.0f : 0.0f,
		g_debugSlider0,
		g_debugSlider1,
		g_debugSlider2,
		g_debugSlider3,
	};
	m_cbDebug.Update(m_pCtx, &cbDebug);
	m_cbDebug.Bind(m_pCtx, CB_DEBUG);

	RenderShadowMap();

	for (int i = 0; i < g_repeatRenderingCount; ++i)
		RenderScene();

	m_gpup.Mark(m_pCtx, GTS_Scene);

	if (m_vrSliMode)
	{
		// Copy the right eye from GPU1 back to GPU0
		D3D11_BOX srcBox = { g_dimsPreWarp.x / 2, 0, 0, g_dimsPreWarp.x, g_dimsPreWarp.y, 1 };
		CHECK_NVAPI_WARN(m_pMultiGPUDevice->CopySubresourceRegion(m_pCtx, m_rtPreWarp.m_pTex, 0, 0, g_dimsPreWarp.x / 2, 0, 0, m_rtPreWarp.m_pTex, 0, 1, &srcBox));
	}

	m_gpup.Mark(m_pCtx, GTS_CrossGPUCopy);

	bool vrDisplayLost = false;
	if (m_oculusSession)
	{
		// Blit the frame to the Oculus swap texture set (would have rendered directly to it,
		// but then it seems you can't blit from it to the back buffer - we just get black).
		// this was the case in the 0.8 SDK, but not sure if it's still true in 1.3
		int currentIndex = -1;
		ovr_GetTextureSwapChainCurrentIndex(m_oculusSession, m_oculusTextureSwapChain, &currentIndex);
		ID3D11RenderTargetView* pRTV = m_oculusSwapTextureRTVs[currentIndex];
		m_pCtx->OMSetRenderTargets(1, &pRTV, nullptr);

		// make sure that pRtFinal is transferred 1:1 onto the swap chain
		SetViewport(m_pCtx, makeint2(g_dimsEyeView.x * 2, g_dimsEyeView.y));
		D3D11_RECT scissor = { 0, 0, g_dimsEyeView.x * 2, g_dimsEyeView.y };
		m_pCtx->RSSetScissorRects(1, &scissor);
		BlitFullscreen(m_pCtx, m_rtPreWarp.m_pSrv);

		// Commit changes to the swap chain
		ovr_CommitTextureSwapChain(m_oculusSession, m_oculusTextureSwapChain);

		// Submit the frame to the Oculus runtime
		ovrLayerEyeFov layerMain = {};
		layerMain.Header.Type = ovrLayerType_EyeFov;
		layerMain.Header.Flags = ovrLayerFlag_HighQuality;
		layerMain.ColorTexture[0] = m_oculusTextureSwapChain;
		layerMain.Viewport[ovrEye_Left].Size.w = g_dimsEyeView.x;
		layerMain.Viewport[ovrEye_Left].Size.h = g_dimsEyeView.y;
		layerMain.Viewport[ovrEye_Right].Pos.x = g_dimsEyeView.x;
		layerMain.Viewport[ovrEye_Right].Size.w = g_dimsEyeView.x;
		layerMain.Viewport[ovrEye_Right].Size.h = g_dimsEyeView.y;
		layerMain.Fov[ovrEye_Left] = m_eyeFovOculusHMD[ovrEye_Left];
		layerMain.Fov[ovrEye_Right] = m_eyeFovOculusHMD[ovrEye_Right];
		layerMain.RenderPose[ovrEye_Left] = m_poseOculusHMD[ovrEye_Left];
		layerMain.RenderPose[ovrEye_Right] = m_poseOculusHMD[ovrEye_Right];
		ovrLayerHeader * layerList[] = { &layerMain.Header };
		ovrResult result = ovr_SubmitFrame(m_oculusSession, m_timer.m_frameCount, nullptr, layerList, dim(layerList));
		if (result == ovrError_DisplayLost)
		{
			// Display was powered off, or something. Set flag to turn off VR mode next frame.
			vrDisplayLost = true;
		}
		else if (OVR_FAILURE(result))
		{
			ovrErrorInfo errorInfo;
			ovr_GetLastErrorInfo(&errorInfo);
			WARN("ovr_SubmitFrame failed with error code: %d\nError message: %s", result, errorInfo.ErrorString);
		}
	}
	else if (m_pOpenVRHMD)
	{
		// Submit the frame to the OpenVR runtime
		vr::Texture_t tex = { m_rtPreWarp.m_pTex, vr::API_DirectX, vr::ColorSpace_Gamma };
		vr::VRTextureBounds_t bounds = { 0.0f, 0.0f, 0.5f, 1.0f };
		CHECK_OPENVR_WARN(m_pCompositorOpenVRHMD->Submit(vr::Eye_Left, &tex, &bounds));
		bounds = { 0.5f, 0.0f, 1.0f, 1.0f };
		CHECK_OPENVR_WARN(m_pCompositorOpenVRHMD->Submit(vr::Eye_Right, &tex, &bounds));
	}

	// Render the main window
	m_pCtx->ClearRenderTargetView(m_pRtvRaw, makergba(0.0f));
	m_pCtx->OMSetDepthStencilState(m_pDssNoDepthTest, 0);
	BindSRGBBackBuffer(m_pCtx);
	BlitFullscreen(m_pCtx, m_rtPreWarp.m_pSrv);

	CHECK_WARN(TwDraw());

	// Present to window - no vsync in VR mode; assume the VR API will take care of that
	CHECK_D3D(m_pSwapChain->Present((g_vsync && !m_oculusSession && !m_pOpenVRHMD) ? 1 : 0, 0));

	m_gpup.OnFrameEnd(m_pCtx);
	m_pCtx->Flush();

	// Turn off VR mode if we lost the headset. This is deferred to end of frame
	// because it can resize render targets and things like that.
	if (vrDisplayLost)
		DeactivateOculusHMD();
}

void VRSLIDemo::DrawMaterials(ID3D11PixelShader * pPs, ID3D11PixelShader * pPsAlphaTest)
{
	// Draw the individual material ranges of the mesh

	// Non-alpha-tested materials
	m_pCtx->PSSetShader(pPs, nullptr, 0);
	m_pCtx->RSSetState(m_pRsDefault);
	for (int i = 0, c = int(m_meshCrytekSponza.m_mtlRanges.size()); i < c; ++i)
	{
		Material * pMtl = m_meshCrytekSponza.m_mtlRanges[i].m_pMtl;
		ASSERT_ERR(pMtl);

		if (pMtl->m_alphaTest)
			continue;

		if (pPs)
		{
			ID3D11ShaderResourceView * pSrvDiffuse = m_tex1x1White.m_pSrv;
			if (Texture2D * pTex = pMtl->m_pTexDiffuseColor)
				pSrvDiffuse = pTex->m_pSrv;
			m_pCtx->PSSetShaderResources(TEX_DIFFUSE, 1, &pSrvDiffuse);

			ID3D11ShaderResourceView * pSrvNormal = m_tex1x1FlatNormal.m_pSrv;
			if (Texture2D * pTex = pMtl->m_pTexHeight)
				pSrvNormal = pTex->m_pSrv;
			m_pCtx->PSSetShaderResources(TEX_NORMAL, 1, &pSrvNormal);
		}

		m_meshCrytekSponza.DrawMtlRange(m_pCtx, i);
	}

	// Alpha-tested materials
	m_pCtx->PSSetShader(pPsAlphaTest, nullptr, 0);
	m_pCtx->RSSetState(m_pRsDoubleSided);
	for (int i = 0, c = int(m_meshCrytekSponza.m_mtlRanges.size()); i < c; ++i)
	{
		Material * pMtl = m_meshCrytekSponza.m_mtlRanges[i].m_pMtl;
		ASSERT_ERR(pMtl);

		if (!pMtl->m_alphaTest)
			continue;

		if (pPsAlphaTest)
		{
			ID3D11ShaderResourceView * pSrvDiffuse = m_tex1x1White.m_pSrv;
			if (Texture2D * pTex = pMtl->m_pTexDiffuseColor)
				pSrvDiffuse = pTex->m_pSrv;
			m_pCtx->PSSetShaderResources(TEX_DIFFUSE, 1, &pSrvDiffuse);

			ID3D11ShaderResourceView * pSrvNormal = m_tex1x1FlatNormal.m_pSrv;
			if (Texture2D * pTex = pMtl->m_pTexHeight)
				pSrvNormal = pTex->m_pSrv;
			m_pCtx->PSSetShaderResources(TEX_NORMAL, 1, &pSrvNormal);
		}

		m_meshCrytekSponza.DrawMtlRange(m_pCtx, i);
	}
}

affine3 VRSLIDemo::GetEyeToCameraTransform(int eye)
{
	if (m_oculusSession)
	{
		ovrPosef hmdPose = m_poseOculusHMD[eye];
		float3 hmdOffset = makefloat3(
			hmdPose.Position.x,
			hmdPose.Position.y,
			hmdPose.Position.z);
		quat hmdOrientation = makequat(
			hmdPose.Orientation.w,
			hmdPose.Orientation.x,
			hmdPose.Orientation.y,
			hmdPose.Orientation.z);

		return makeaffine3(hmdOrientation, hmdOffset);
	}
	else if (m_pOpenVRHMD)
	{
		vr::Hmd_Eye currentEye = eye ? vr::Hmd_Eye::Eye_Right : vr::Hmd_Eye::Eye_Left;
		vr::HmdMatrix34_t matEyeToHmd = m_pOpenVRHMD->GetEyeToHeadTransform(currentEye);
		affine3 eyeToHmd = makeaffine3(
			matEyeToHmd.m[0][0], matEyeToHmd.m[1][0], matEyeToHmd.m[2][0],
			matEyeToHmd.m[0][1], matEyeToHmd.m[1][1], matEyeToHmd.m[2][1],
			matEyeToHmd.m[0][2], matEyeToHmd.m[1][2], matEyeToHmd.m[2][2],
			matEyeToHmd.m[0][3], matEyeToHmd.m[1][3], matEyeToHmd.m[2][3]);

		return eyeToHmd * m_poseOpenVRHMD;
	}
	else
	{
		// Hard coded eye offset, so we can have some stereo rendering even without an HMD
		float eyeOffset = 0.032f * (eye ? 1.0f : -1.0f);
		return translation(makefloat3(eyeOffset, 0.0f, 0.0f));
	}
}

void VRSLIDemo::RenderScene()
{
	m_pCtx->IASetInputLayout(m_pInputLayout);
	m_pCtx->OMSetDepthStencilState(m_pDssDepthTest, 0);

	// Crytek Sponza is authored in centimeters; convert to meters
	float sceneScale = 0.01f;

	CBFrame cbFrame =
	{
		{},
		affineToHomogeneous(scaling(makefloat3(sceneScale))) * m_shmp.m_matWorldToUvzw,
		makematrix<float, 3, 4>(m_shmp.m_matWorldToUvzNormal),
		{},
		0,
		g_vecDirectionalLight,
		0,
		g_rgbDirectionalLight,
		0,
		m_shmp.CalcFilterUVZScale(g_shadowFilterWidth),
		g_normalOffsetShadow,
		g_exposure,
	};

	// Clear all buffers we're about to render to
	m_pCtx->ClearRenderTargetView(m_rtPreWarpMSAA.m_pRtv, toLinear(makergba(g_rgbSky, 1.0f)));
	m_pCtx->ClearDepthStencilView(m_dstPreWarpMSAA.m_pDsv, D3D11_CLEAR_DEPTH, 1.0f, 0);

	BindRenderTargets(m_pCtx, &m_rtPreWarpMSAA, &m_dstPreWarpMSAA);

	m_pCtx->IASetInputLayout(m_pInputLayout);
	m_pCtx->VSSetShader(m_pVsWorld, nullptr, 0);

	m_pCtx->PSSetShaderResources(TEX_SHADOW, 1, &m_shmp.m_dst.m_pSrvDepth);
	m_pCtx->PSSetSamplers(SAMP_DEFAULT, 1, &m_pSsTrilinearRepeatAniso);
	m_pCtx->PSSetSamplers(SAMP_SHADOW, 1, &m_pSsPCF);

	if (m_vrSliMode && m_useBroadcastSLI)
	{
		// Code to draw scene using broadcast mode: setting up per-GPU constant buffers and viewports,
		// then rendering the scene once

		m_pMultiGPUDevice->SetGPUMask(NVAPI_ALL_GPUS);

		// Calculate world-to-clip matrix for each eye
		for (int eye = 0; eye < 2; ++eye)
		{
			affine3 eyeToCamera = GetEyeToCameraTransform(eye);
			affine3 eyeToWorld = eyeToCamera * m_camCrytekSponza.m_viewToWorld;
			affine3 worldToEye = transpose(eyeToWorld);
			float4x4 worldToClip = affineToHomogeneous(scaling(makefloat3(sceneScale)) * worldToEye) * m_matProj[eye];

			// Update constant buffer data for the new matrices
			cbFrame.m_matWorldToClip = worldToClip;
			cbFrame.m_posCamera = makepoint3(eyeToWorld.m_translation);
			m_cbFrame[eye].Update(m_pCtx, &cbFrame);
		}

		// Bind both constant buffers, one on each GPU
		ID3D11Buffer * buffers[2] = { m_cbFrame[0].m_pBuf, m_cbFrame[1].m_pBuf };
		CHECK_NVAPI_WARN(m_pMultiGPUDevice->VSSetConstantBuffers(m_pCtx, NVAPI_ALL_GPUS, CB_FRAME, 1, buffers));
		CHECK_NVAPI_WARN(m_pMultiGPUDevice->PSSetConstantBuffers(m_pCtx, NVAPI_ALL_GPUS, CB_FRAME, 1, buffers));

		// Set both viewports, one on each GPU
		D3D11_VIEWPORT viewports[2] =
		{
			{ 0, 0, float(g_dimsPreWarp.x / 2), float(g_dimsPreWarp.y), 0, 1 },								// Left
			{ float(g_dimsPreWarp.x / 2), 0, float(g_dimsPreWarp.x / 2), float(g_dimsPreWarp.y), 0, 1 },	// Right
		};
		CHECK_NVAPI_WARN(m_pMultiGPUDevice->SetViewports(m_pCtx, NVAPI_ALL_GPUS, 1, viewports));

		DrawMaterials(m_pPsSimple, m_pPsSimpleAlphaTest);
	}
	else
	{
		// Code to draw the two eyes separately, either for single-GPU mode or using affinity masking
		for (int eye = 0; eye < 2; ++eye)
		{
			// In VR SLI mode, draw each eye on its own GPU; otherwise, draw everything on GPU0
			if (m_pMultiGPUDevice)
				m_pMultiGPUDevice->SetGPUMask(m_vrSliMode ? (1 << eye) : 1);

			// Calculate world-to-clip matrix for this eye
			affine3 eyeToCamera = GetEyeToCameraTransform(eye);
			affine3 eyeToWorld = eyeToCamera * m_camCrytekSponza.m_viewToWorld;
			affine3 worldToEye = transpose(eyeToWorld);
			float4x4 worldToClip = affineToHomogeneous(scaling(makefloat3(sceneScale)) * worldToEye) * m_matProj[eye];

			// Update constant buffer data for the new matrices
			cbFrame.m_matWorldToClip = worldToClip;
			cbFrame.m_posCamera = makepoint3(eyeToWorld.m_translation);
			m_cbFrame[0].Update(m_pCtx, &cbFrame);
			m_cbFrame[0].Bind(m_pCtx, CB_FRAME);

			// Set viewport to half of the render target
			SetViewport(m_pCtx, makebox2(float(g_dimsPreWarp.x / 2 * eye), 0.0f, float(g_dimsPreWarp.x / 2 * (eye + 1)), float(g_dimsPreWarp.y)));

			DrawMaterials(m_pPsSimple, m_pPsSimpleAlphaTest);
		}
	}

	// Custom resolve + tonemapping pass: from MSAA RGBA16F buffer into non-MSAA RGBA8 SRGB buffer.
	// Always broadcast since the operations are the same on both GPUs.

	if (m_vrSliMode)
		m_pMultiGPUDevice->SetGPUMask(NVAPI_ALL_GPUS);

	m_pCtx->RSSetState(m_pRsDefault);
	m_pCtx->OMSetDepthStencilState(m_pDssNoDepthTest, 0);
	m_pCtx->OMSetRenderTargets(1, &m_pRtvPreWarpRaw, nullptr);
	SetViewport(m_pCtx, m_rtPreWarp.m_dims);

	m_pCtx->PSSetShader(m_pPsTonemap, nullptr, 0);
	m_pCtx->PSSetShaderResources(0, 1, &m_rtPreWarpMSAA.m_pSrv);
	DrawFullscreenPass(m_pCtx);

	// Unbind the CB and SRV to keep the debug layer happy
	ID3D11Buffer * pCBNull = nullptr;
	m_pCtx->VSSetConstantBuffers(0, 1, &pCBNull);
	ID3D11ShaderResourceView * pSrvNull = nullptr;
	m_pCtx->PSSetShaderResources(0, 1, &pSrvNull);
}

void VRSLIDemo::RenderShadowMap()
{
	// Draw the shadow map on all GPUs so it'll be available later,
	// regardless whether VR SLI mode is on at the moment
	if (m_pMultiGPUDevice)
		m_pMultiGPUDevice->SetGPUMask(NVAPI_ALL_GPUS);

	// Crytek Sponza is authored in centimeters; convert to meters
	float sceneScale = 0.01f;

	// Calculate shadow map matrices
	float4x4 matWorldToClipPrev = m_shmp.m_matWorldToClip;
	m_shmp.m_vecLight = g_vecDirectionalLight;
	m_shmp.m_boundsScene = makebox3(m_meshCrytekSponza.m_bounds.m_mins * sceneScale, m_meshCrytekSponza.m_bounds.m_maxs * sceneScale);
	m_shmp.UpdateMatrix();

	// Only re-render if the matrix changed, to save perf
	if (all(isnear(m_shmp.m_matWorldToClip, matWorldToClipPrev)))
		return;

	m_pCtx->IASetInputLayout(m_pInputLayout);
	m_pCtx->OMSetDepthStencilState(m_pDssDepthTest, 0);

	CBFrame cbFrame =
	{
		affineToHomogeneous(scaling(makefloat3(sceneScale))) * m_shmp.m_matWorldToClip,
	};
	m_cbFrame[0].Update(m_pCtx, &cbFrame);
	m_cbFrame[0].Bind(m_pCtx, CB_FRAME);

	m_pCtx->ClearDepthStencilView(m_shmp.m_dst.m_pDsv, D3D11_CLEAR_DEPTH, 1.0f, 0);
	m_shmp.Bind(m_pCtx);

	m_pCtx->VSSetShader(m_pVsWorld, nullptr, 0);
	m_pCtx->PSSetSamplers(SAMP_DEFAULT, 1, &m_pSsTrilinearRepeatAniso);

	DrawMaterials(nullptr, m_pPsShadowAlphaTest);
}

void VRSLIDemo::ResetCameras()
{
	m_camCrytekSponza.LookAt(
					makepoint3(-8.7f, 6.8f, 0.0f),
					makepoint3(0.0f, 5.0f, 0.0f));
}

bool VRSLIDemo::TryActivateOculusHMD()
{
	if (m_oculusSession)
		return true;

	DeactivateOpenVRHMD();
	DeactivateOculusHMD();

	// Connect to HMD
	ovrGraphicsLuid oculusLuid = {};
	if (OVR_FAILURE(ovr_Create(&m_oculusSession, &oculusLuid)))
		return false;
	ASSERT_ERR(m_oculusSession);

	// Check that the adapter LUID matches our DX11 device
	comptr<IDXGIDevice> pDXGIDevice;
	CHECK_D3D(m_pDevice->QueryInterface<IDXGIDevice>(&pDXGIDevice));
	comptr<IDXGIAdapter> pAdapter;
	CHECK_D3D(pDXGIDevice->GetAdapter(&pAdapter));
	DXGI_ADAPTER_DESC adapterDesc;
	CHECK_D3D(pAdapter->GetDesc(&adapterDesc));
	adapterDesc.AdapterLuid;
	cassert(sizeof(adapterDesc.AdapterLuid) == sizeof(oculusLuid));
	if (memcmp(&adapterDesc.AdapterLuid, &oculusLuid, sizeof(oculusLuid)) != 0)
	{
		ERR("Oculus VR headset is connected to a different GPU than the app is running on.");
		return false;
	}

	// Set new render target size
	ovrHmdDesc hmdDesc = ovr_GetHmdDesc(m_oculusSession);
	ovrSizei eyeSizeLeft = ovr_GetFovTextureSize(m_oculusSession, ovrEye_Left, hmdDesc.DefaultEyeFov[0], 1.0f);
	ovrSizei eyeSizeRight = ovr_GetFovTextureSize(m_oculusSession, ovrEye_Right, hmdDesc.DefaultEyeFov[1], 1.0f);
	g_dimsEyeView = makeint2(max(eyeSizeLeft.w, eyeSizeRight.w), max(eyeSizeLeft.h, eyeSizeRight.h));
	int2 dimsRenderTarget = { g_dimsEyeView.x * 2, g_dimsEyeView.y };
	UpdateRenderTargetDims();

	// Create texture swap chain for both eyes side-by-side
	ovrTextureSwapChainDesc swapDesc =
	{
		ovrTexture_2D,
		OVR_FORMAT_R8G8B8A8_UNORM_SRGB,
		1, dimsRenderTarget.x, dimsRenderTarget.y, 1, 1,
		ovrFalse,
		ovrTextureMisc_DX_Typeless,
		ovrTextureBind_DX_RenderTarget
	};
	CHECK_OVR(ovr_CreateTextureSwapChainDX(
		m_oculusSession, m_pDevice, &swapDesc, &m_oculusTextureSwapChain
		));
	ASSERT_ERR(m_oculusTextureSwapChain);

	D3D11_RENDER_TARGET_VIEW_DESC rtvDesc = {};
	rtvDesc.ViewDimension = D3D11_RTV_DIMENSION_TEXTURE2D;
	rtvDesc.Format = DXGI_FORMAT_R8G8B8A8_UNORM_SRGB;
	rtvDesc.Texture2D.MipSlice = 0;

	m_oculusSwapTextureRTVs.clear();

	int swapLength = 0;
	ovr_GetTextureSwapChainLength(m_oculusSession, m_oculusTextureSwapChain, &swapLength);
	m_oculusSwapTextureRTVs.resize(swapLength);
	for (int nTexture = 0; nTexture < swapLength; nTexture++)
	{
		ID3D11Texture2D* swapTex = nullptr;
		ovr_GetTextureSwapChainBufferDX(m_oculusSession, m_oculusTextureSwapChain, nTexture, IID_PPV_ARGS(&swapTex));
		CHECK_D3D(m_pDevice->CreateRenderTargetView(swapTex, &rtvDesc, &m_oculusSwapTextureRTVs[nTexture]));
	}

	// Set new projection matrices
	for (int i = 0; i < 2; ++i)
	{
		float zNear = 0.01f;
		float zFar = 1000.0f;

		m_matProj[i] = perspProjD3DStyle(
							-hmdDesc.DefaultEyeFov[i].LeftTan * zNear,
							hmdDesc.DefaultEyeFov[i].RightTan * zNear,
							-hmdDesc.DefaultEyeFov[i].DownTan * zNear,
							hmdDesc.DefaultEyeFov[i].UpTan * zNear,
							zNear,
							zFar);

		// Store the fovport and eye offset vectors for later use
		m_eyeFovOculusHMD[i] = hmdDesc.DefaultEyeFov[i];
		ovrEyeRenderDesc eyeRenderDesc = ovr_GetRenderDesc(m_oculusSession, ovrEyeType(i), hmdDesc.DefaultEyeFov[i]);
		m_eyeOffsetsOculusHMD[i] = eyeRenderDesc.HmdToEyeOffset;
	}

	return true;
}

void VRSLIDemo::DeactivateOculusHMD()
{
	m_oculusSwapTextureRTVs.clear();
	if (m_oculusTextureSwapChain)
	{
		ovr_DestroyTextureSwapChain(m_oculusSession, m_oculusTextureSwapChain);
		m_oculusTextureSwapChain = nullptr;
	}

	if (m_oculusSession)
	{
		ovr_Destroy(m_oculusSession);
		m_oculusSession = nullptr;
	}

	SetRenderTargetDimsToMatchWindow();
}

bool VRSLIDemo::TryActivateOpenVRHMD()
{
	if (m_pOpenVRHMD)
		return true;

	DeactivateOculusHMD();
	DeactivateOpenVRHMD();

	if (!vr::VR_IsHmdPresent())
		return false;

	// Loading the SteamVR Runtime
	vr::EVRInitError eError = vr::VRInitError_None;
	m_pOpenVRHMD = vr::VR_Init(&eError, vr::VRApplication_Scene);

	if (eError != vr::VRInitError_None)
	{
		m_pOpenVRHMD = nullptr;
		ERR("Unable to init VR runtime: %s", vr::VR_GetVRInitErrorAsEnglishDescription(eError));
		return false;
	}

	// Init compositor.
	vr::EVRInitError peError = vr::VRInitError_None;

	m_pCompositorOpenVRHMD = (vr::IVRCompositor*)vr::VR_GetGenericInterface(vr::IVRCompositor_Version, &peError);

	if (peError != vr::VRInitError_None)
	{
		m_pCompositorOpenVRHMD = nullptr;
		ERR("Compositor initialization failed with error: %s", vr::VR_GetVRInitErrorAsEnglishDescription(peError));
		DeactivateOpenVRHMD();
		return false;
	}

	// Set new render target size
	uint32_t rtWidth, rtHeight;
	m_pOpenVRHMD->GetRecommendedRenderTargetSize(&rtWidth, &rtHeight);
	g_dimsEyeView = makeint2(rtWidth, rtHeight);
	UpdateRenderTargetDims();

	// Set new projection matrices
	vr::HmdMatrix44_t proj;
	proj = m_pOpenVRHMD->GetProjectionMatrix(vr::Hmd_Eye::Eye_Left, 0.01f, 1000.0f, vr::API_DirectX);
	m_matProj[0] = transpose(makefloat4x4(&proj.m[0][0]));
	proj = m_pOpenVRHMD->GetProjectionMatrix(vr::Hmd_Eye::Eye_Right, 0.01f, 1000.0f, vr::API_DirectX);
	m_matProj[1] = transpose(makefloat4x4(&proj.m[0][0]));

	return true;
}

void VRSLIDemo::DeactivateOpenVRHMD()
{
	if (m_pOpenVRHMD)
	{
		vr::VR_Shutdown();
		m_pOpenVRHMD = nullptr;
		m_pCompositorOpenVRHMD = nullptr;
	}

	SetRenderTargetDimsToMatchWindow();
}

void VRSLIDemo::SaveScreenshot(RenderTarget * pRt, const char * suggestedFilename)
{
	ASSERT_ERR(pRt);

	// Call Windows common file dialog to get a filename to save the screenshot to

	char path[MAX_PATH] = {};
	strcpy_s(path, suggestedFilename);

	OPENFILENAME ofn = {};
	ofn.lStructSize = sizeof(ofn);
	ofn.hwndOwner = m_hWnd;
	ofn.hInstance = m_hInstance;
	ofn.lpstrFilter = "Bitmap Files (*.bmp)\0*.bmp\0";
	ofn.nFilterIndex = 1;
	ofn.lpstrFile = path;
	ofn.nMaxFile = dim(path);
	ofn.lpstrTitle = "Save Screenshot";
	ofn.Flags = OFN_PATHMUSTEXIST | OFN_OVERWRITEPROMPT;

	if (!GetSaveFileName(&ofn))
	{
		// User clicked cancel, so don't do anything.
		return;
	}

	CHECK_WARN(WriteRenderTargetToBMP(m_pCtx, pRt, path));
}



// Get the whole shebang going

int WINAPI WinMain(HINSTANCE hInstance, HINSTANCE hPrevInstance, LPSTR lpCmdLine, int nCmdShow)
{
	(void)hPrevInstance;
	(void)lpCmdLine;
	(void)nCmdShow;

	VRSLIDemo demo;
	if (!demo.Init(hInstance))
	{
		demo.Shutdown();
		return 1;
	}

	demo.MainLoop(SW_SHOWMAXIMIZED);
	return 0;
}
